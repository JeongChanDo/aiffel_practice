{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from tensorflow.keras.initializers import Constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_to_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f556127ffef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword_vector_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;31m# 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vector_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_to_index' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(512, 14, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "model.add(keras.layers.Conv1D(512, 14, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 32)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 10, 128)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6.7418545e-01 -2.8626782e-01 -2.3915540e-01 ...  1.8930699e-01\n",
      "  -1.9417613e+00 -1.1867785e+00]\n",
      " [-1.9895293e-01  1.8146215e-01  8.7643528e-01 ...  4.5543870e-01\n",
      "   3.3444798e-01  3.3205020e-01]\n",
      " [ 5.6640977e-01  1.1480675e+00  1.4531080e-01 ...  1.3020878e+00\n",
      "   1.9847550e-03 -1.3159907e+00]\n",
      " ...\n",
      " [-1.7830979e+00  7.6262601e-02 -1.2993813e-01 ... -5.5149174e-01\n",
      "  -1.7748146e+00  2.3595302e+00]\n",
      " [-5.3864878e-01  7.7050328e-01 -1.5593674e+00 ... -3.9921455e-02\n",
      "  -1.0991867e+00  7.0396554e-01]\n",
      " [-1.6182830e+00 -4.2390618e-01 -5.4913646e-01 ... -8.2374012e-01\n",
      "  -9.1019921e-02  1.7651708e+00]], shape=(100, 43), dtype=float32)\n",
      "(100, 43)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c7d6dbd4710a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vector_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "input_shape = (100, 43)\n",
    "vocab_size = 10\n",
    "word_vector_dim = 5\n",
    "x = tf.random.normal(input_shape)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "y = keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 3)           15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv1D(3, 2, activation='relu', input_shape=(None, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 4)           20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv1D(4, 2, activation='relu', input_shape=(None, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 128)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, None, 32)          4512      \n",
      "=================================================================\n",
      "Total params: 4,512\n",
      "Trainable params: 4,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 10, 128)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n",
    "y = keras.layers.MaxPooling1D(2) (x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 12, 512)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 43, 100)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv1D(512, 32, activation=\"relu\")(x)\n",
    "#y = keras.layers.MaxPooling1D(2) (x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 100)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 43, 100)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv1D(512, 32, activation=\"relu\")(x)\n",
    "y = keras.layers.MaxPooling1D(7) (x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 21, 100)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 43, 100)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv1D(512, 32, activation=\"relu\")(x)\n",
    "y = keras.layers.MaxPooling1D(2) (x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 2, 32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 3, 2, 32)          320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(4, 3, 2, 32)\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = 5, 4\n",
    "nums, ch = 4, 1\n",
    "\n",
    "\n",
    "input_shape = (nums, img_w, img_h, ch)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "print(y.shape)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_w, img_h, ch)))\n",
    "model.summary()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 4, 32)\n",
      "(4, 4, 3, 32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 5, 4, 32)          320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 3, 32)          0         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = 7, 6\n",
    "nums, ch = 4, 1\n",
    "\n",
    "\n",
    "input_shape = (nums, img_w, img_h, ch)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "print(y.shape)\n",
    "y = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(y)\n",
    "print(y.shape)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_w, img_h, ch)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 4, 32)\n",
      "(4, 4, 3, 32)\n",
      "(4, 2, 1, 32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 5, 4, 32)          320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 2, 16)          2064      \n",
      "=================================================================\n",
      "Total params: 2,384\n",
      "Trainable params: 2,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = 7, 6\n",
    "nums, ch = 4, 1\n",
    "\n",
    "\n",
    "input_shape = (nums, img_w, img_h, ch)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "print(y.shape)\n",
    "y = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(y)\n",
    "print(y.shape)\n",
    "y = keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(y)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_w, img_h, ch)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "model.add(keras.layers.Conv2D(16, (2,2), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 1)\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]], shape=(1, 5, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\n",
       "array([[[2.],\n",
       "        [4.]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1., 2., 3., 4., 5.])\n",
    "x = tf.reshape(x, [1, 5, 1])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2, padding='valid')\n",
    "max_pool_1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 1)\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]], shape=(1, 5, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\n",
       "array([[[2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.]]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1., 2., 3., 4., 5.])\n",
    "x = tf.reshape(x, [1, 5, 1])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding='valid')\n",
    "max_pool_1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 1)\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]\n",
      "  [6.]]], shape=(1, 6, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\n",
       "array([[[3.],\n",
       "        [6.]]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1., 2., 3., 4., 5., 6.])\n",
    "x = tf.reshape(x, [1, 6, 1])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')\n",
    "max_pool_1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = 50\n",
    "vocab_size =  43\n",
    "word_vector_dim = 100\n",
    "\n",
    "input_shape = (nums, img_w, img_h, ch)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "print(y.shape)\n",
    "y = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(y)\n",
    "print(y.shape)\n",
    "y = keras.layers.Conv2D(32, (3, 3), activation=\"relu\")(y)\n",
    "print(y.shape)\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(512, 14, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(2))\n",
    "model.add(keras.layers.Conv1D(512, 14, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 43, 100)           100000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 37, 16)            11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 113,169\n",
      "Trainable params: 113,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "nums = 50\n",
    "sentence_len = 43\n",
    "vocab_size =  1000\n",
    "word_vector_dim = 100\n",
    "\n",
    "cnn = keras.Sequential()\n",
    "cnn.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(sentence_len,)))\n",
    "cnn.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn.add(keras.layers.MaxPooling1D(5))\n",
    "cnn.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn.add(keras.layers.GlobalMaxPooling1D())\n",
    "cnn.add(keras.layers.Dense(8, activation='relu'))\n",
    "cnn.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 100)         10000000  \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 512)         0         \n",
      "=================================================================\n",
      "Total params: 16,554,112\n",
      "Trainable params: 16,554,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 100000  # 어휘 사전의 크기    ###################################이게 크기가 작으면 모델 훈련이 안 된다 왜?\n",
    "word_vector_dim = 100   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(512, 128, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 100)         10000000  \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 512)         33554944  \n",
      "=================================================================\n",
      "Total params: 50,109,056\n",
      "Trainable params: 50,109,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 100000  # 어휘 사전의 크기    ###################################이게 크기가 작으면 모델 훈련이 안 된다 왜?\n",
    "word_vector_dim = 100   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(512, 128, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D())\n",
    "model.add(keras.layers.Conv1D(512, 128, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
